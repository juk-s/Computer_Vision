{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7482a927",
   "metadata": {},
   "source": [
    "# ЛР2 — трекинг объекта по ключевым точкам (новый ноутбук)\n",
    "\n",
    "Свежая версия лабораторной работы без опоры на предыдущие блокноты. Используется классический подход: ключевые точки ORB, сопоставление `BFMatcher`, оценка гомографии через RANSAC и прорисовка рамки объекта на каждом кадре.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b650c0",
   "metadata": {},
   "source": [
    "## Алгоритм\n",
    "- Первый кадр видео берётся как шаблон объекта.\n",
    "- Шаблон переводится в градации серого, по желанию применяется CLAHE.\n",
    "- Строится пирамида шаблонов по масштабу, для каждой копии считаются ключевые точки и дескрипторы ORB.\n",
    "- Для каждого кадра: детектируются признаки, сопоставляются с каждым масштабом шаблона (ratio test), по лучшей группе ищется гомография (RANSAC).\n",
    "- Если число инлаеров достаточно — рисуется проецированный контур объекта и подпись; иначе выводится `Object not found`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafdca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e00e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_orb(nfeatures: int = 2000, scale_factor: float = 1.2, nlevels: int = 8) -> cv2.ORB:\n",
    "    \"\"\"Конфигурация ORB с запасом по ключевым точкам.\"\"\"\n",
    "    return cv2.ORB_create(\n",
    "        nfeatures=nfeatures,\n",
    "        scaleFactor=scale_factor,\n",
    "        nlevels=nlevels,\n",
    "        edgeThreshold=15,\n",
    "        patchSize=31,\n",
    "    )\n",
    "\n",
    "\n",
    "def preprocess_gray(frame: np.ndarray, use_clahe: bool = False) -> np.ndarray:\n",
    "    \"\"\"BGR -> серый; опционально CLAHE для подъёма контраста.\"\"\"\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    if use_clahe:\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "        gray = clahe.apply(gray)\n",
    "    return gray\n",
    "\n",
    "\n",
    "def detect_features(detector: cv2.Feature2D, gray: np.ndarray) -> Tuple[List[cv2.KeyPoint], np.ndarray]:\n",
    "    keypoints, descriptors = detector.detectAndCompute(gray, None)\n",
    "    if descriptors is None:\n",
    "        descriptors = np.zeros((0, detector.descriptorSize()), dtype=np.uint8)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "\n",
    "def build_template_pyramid(template_gray: np.ndarray, detector: cv2.Feature2D, scales: Tuple[float, ...]) -> List[Dict]:\n",
    "    \"\"\"Создаёт набор шаблонов разных масштабов со своими признаками.\"\"\"\n",
    "    templates = []\n",
    "    for scale in scales:\n",
    "        resized = cv2.resize(template_gray, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "        kp, desc = detect_features(detector, resized)\n",
    "        if len(kp) == 0 or len(desc) == 0:\n",
    "            continue\n",
    "        h, w = resized.shape[:2]\n",
    "        corners = np.float32([[0, 0], [w, 0], [w, h], [0, h]]).reshape(-1, 1, 2)\n",
    "        templates.append({\"scale\": scale, \"kp\": kp, \"desc\": desc, \"corners\": corners})\n",
    "    return templates\n",
    "\n",
    "\n",
    "def match_with_ratio(matcher: cv2.BFMatcher, desc1: np.ndarray, desc2: np.ndarray, ratio: float) -> List[cv2.DMatch]:\n",
    "    if len(desc1) == 0 or len(desc2) == 0:\n",
    "        return []\n",
    "    knn = matcher.knnMatch(desc1, desc2, k=2)\n",
    "    good = [m for m, n in knn if m.distance < ratio * n.distance]\n",
    "    return good\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eec474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_object(\n",
    "    video_path: str,\n",
    "    output_path: str,\n",
    "    *,\n",
    "    ratio: float = 0.78,\n",
    "    min_matches: int = 12,\n",
    "    min_inliers: int = 10,\n",
    "    scales: Tuple[float, ...] = (1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4),\n",
    "    use_clahe: bool = True,\n",
    "    verbose: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"Трекинг объекта по первому кадру, результат сохраняется в mp4.\"\"\"\n",
    "    video_path = Path(video_path)\n",
    "    output_path = Path(output_path)\n",
    "\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(f\"Не удалось открыть видео: {video_path}\")\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    ok, first_frame = cap.read()\n",
    "    if not ok:\n",
    "        cap.release()\n",
    "        raise RuntimeError(\"Видео пустое — нет первого кадра\")\n",
    "\n",
    "    detector = make_orb()\n",
    "    template_gray = preprocess_gray(first_frame, use_clahe)\n",
    "    templates = build_template_pyramid(template_gray, detector, scales)\n",
    "    if not templates:\n",
    "        raise RuntimeError(\"Не нашли ключевые точки в шаблоне\")\n",
    "\n",
    "    matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    writer = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))\n",
    "\n",
    "    frame_id = 0\n",
    "    while True:\n",
    "        if frame_id == 0:\n",
    "            frame = first_frame\n",
    "        else:\n",
    "            ok, frame = cap.read()\n",
    "            if not ok:\n",
    "                break\n",
    "        frame_gray = preprocess_gray(frame, use_clahe)\n",
    "        kp_frame, desc_frame = detect_features(detector, frame_gray)\n",
    "        if len(desc_frame) == 0:\n",
    "            writer.write(frame)\n",
    "            frame_id += 1\n",
    "            continue\n",
    "\n",
    "        best = {\"inliers\": 0, \"corners\": None}\n",
    "        for tpl in templates:\n",
    "            good = match_with_ratio(matcher, tpl[\"desc\"], desc_frame, ratio)\n",
    "            if len(good) < min_matches:\n",
    "                continue\n",
    "            src_pts = np.float32([tpl[\"kp\"][m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "            dst_pts = np.float32([kp_frame[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "            H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 4.0)\n",
    "            if H is None or mask is None:\n",
    "                continue\n",
    "            inliers = int(mask.sum())\n",
    "            if inliers > best[\"inliers\"]:\n",
    "                corners = cv2.perspectiveTransform(tpl[\"corners\"], H)\n",
    "                best = {\"inliers\": inliers, \"corners\": corners}\n",
    "\n",
    "        if best[\"corners\"] is not None and best[\"inliers\"] >= min_inliers:\n",
    "            pts = np.int32(best[\"corners\"])\n",
    "            cv2.polylines(frame, [pts], True, (0, 180, 0), 3)\n",
    "            x, y = pts[0, 0]\n",
    "            label = f\"Object ({best['inliers']} inliers)\"\n",
    "            cv2.putText(frame, label, (int(x), int(max(y - 10, 20))), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 220, 220), 2, cv2.LINE_AA)\n",
    "        else:\n",
    "            cv2.putText(frame, \"Object not found\", (24, 36), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        if verbose:\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                f\"kp frame: {len(kp_frame)}\",\n",
    "                (24, height - 20),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.55,\n",
    "                (255, 255, 255),\n",
    "                1,\n",
    "                cv2.LINE_AA,\n",
    "            )\n",
    "        writer.write(frame)\n",
    "        frame_id += 1\n",
    "\n",
    "    cap.release()\n",
    "    writer.release()\n",
    "    return str(output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35555415",
   "metadata": {},
   "source": [
    "## Запуск на тестовом видео `mona-lisa.avi`\n",
    "Код ниже прогоняет трекер и сохраняет результат в `results/lr2_mona_lisa.mp4`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d914c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_video = track_object(\n",
    "    \"mona-lisa.avi\",\n",
    "    \"results/lr2_mona_lisa.mp4\",\n",
    "    ratio=0.78,\n",
    "    min_matches=12,\n",
    "    min_inliers=10,\n",
    "    scales=(1.0, 0.85, 0.7, 0.55, 0.4),\n",
    "    use_clahe=True,\n",
    ")\n",
    "print(f\"Результат сохранён в: {output_video}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
